{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次登陆\n",
      "第一次登陆成功\n",
      "56a914ce806824d9c9043f52460dc5b5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',\n",
    "}\n",
    "def getDSID(user_id = '*********', password = '*********'):    \n",
    "    url = 'https://vpn.hit.edu.cn/dana-na/auth/url_default/login.cgi'\n",
    "    post_data = {\n",
    "        'tz_offset': '480',\n",
    "        'username': user_id,\n",
    "        'password': password,\n",
    "        'realm': '学生',\n",
    "        'btnSubmit': '登陆'\n",
    "    }   \n",
    "    print('第一次登陆')\n",
    "    r = requests.post(url, data = post_data,  allow_redirects = False)\n",
    "    cookies = r.headers.get('Set-Cookie')\n",
    "    \n",
    "    # 如果没有Set-Cookie字段，说明登陆失败，这是尝试把之前的登陆挤掉\n",
    "    if (cookies == None):\n",
    "        print('第一次登陆失败,重新登陆中...')\n",
    "        r = requests.post(url, data = post_data,  allow_redirects = True)\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        from_data_str = soup(id = 'DSIDFormDataStr')[0].get('value')\n",
    "        post_data = {\n",
    "            'btnContinue': '继续会话',\n",
    "            'FormDataStr': from_data_str,\n",
    "        }\n",
    "        r = requests.post(url, data = post_data,  allow_redirects = False)\n",
    "        cookies = r.headers.get('Set-Cookie')\n",
    "        print('第二次登陆成功')\n",
    "    else:\n",
    "        print('第一次登陆成功')\n",
    "    start_index = cookies.find('DSID')\n",
    "    start_index = cookies.find('=', start_index)\n",
    "    end_index = cookies.find(';', start_index)\n",
    "    print(cookies[start_index+1:end_index])\n",
    "    return cookies[start_index+1:end_index]\n",
    "        \n",
    "cookies_dsid = getDSID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将网页中的表格处理成为二维布尔数组\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "import time\n",
    "import functools\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "MAX_THREAD_SIZE = 8\n",
    "MAX_CLASSROOM_NUMBER = 300\n",
    "MAX_WEEK = 18\n",
    "SQL_DIR = 'kjs_sql/'#程序初始化地时候检查文件夹是否存在，写入文件的时候不检查\n",
    "MAX_THREAD_SIZE = 4\n",
    "USE_VPN = True\n",
    "TIMEOUT = 120\n",
    "ALL_INFO_FILE = 'room-info.json'\n",
    "\n",
    "url_vpn = 'https://vpn.hit.edu.cn/kjscx/,DanaInfo=jwts.hit.edu.cn+queryKjs_wdl'\n",
    "url_0 = 'http://jwts.hit.edu.cn/kjscx/queryKjs_wdl'\n",
    "\n",
    "def get_classroom_html(*args, **kwargs):\n",
    "    week, camp_id, building_id = args[0], args[1], args[2]\n",
    "    post_data = {\n",
    "        'pageXnxq': '2019-20201',\n",
    "        'pageZc1': str(week),\n",
    "        'pageZc2': str(week),\n",
    "        'pageXiaoqu': camp_id,\n",
    "        'pageLhdm': building_id,\n",
    "        'pageCddm': '',\n",
    "        'pageSize': MAX_CLASSROOM_NUMBER,\n",
    "    }\n",
    "    r = None\n",
    "    if 'use_vpn' in kwargs.keys() and not kwargs.get('use_vpn'):\n",
    "#         print('no vpn')\n",
    "        r = requests.post(url_0, data = post_data, timeout = TIMEOUT)\n",
    "    else:\n",
    "        cookies = {\n",
    "            'DSID': cookies_dsid,\n",
    "        }\n",
    "        r = requests.post(url_vpn, data = post_data, headers = headers, cookies = cookies)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    soup = soup('table', 'dataTable')\n",
    "#     print(soup)\n",
    "    if (len(soup) == 0):\n",
    "        print('获取网页失败，可能是会话过期或者网站已更新')\n",
    "        return None\n",
    "    else:\n",
    "        return week, soup[0]\n",
    "\n",
    "\n",
    "def table2array(soup):\n",
    "    # 将表格中的一行处理为布尔数组，被table2array调用\n",
    "    def tr2bool_list(tr_soup):\n",
    "        tr_soup = tr_soup('td')[1:]\n",
    "        ite = map(lambda td_cell: 'kjs_icon' in td_cell('div')[0].get('class'), tr_soup)\n",
    "        return list(ite)\n",
    "    \n",
    "    soup = soup('tr')[2:]\n",
    "    ite = map(lambda tr_soup: tr2bool_list(tr_soup), soup)\n",
    "    return list(ite)\n",
    "\n",
    "\n",
    "# 并发地获取一栋教学楼的1-18周的空教室信息，并且存储为文件\n",
    "\n",
    "\n",
    "def write2file(building_id, info_list):\n",
    "    building_id = ('%03d' % (int(building_id)))\n",
    "    classroom_size = len(info_list)\n",
    "    file_path = SQL_DIR + 'room-info-' + building_id + '.json'\n",
    "    with open(file_path, 'a') as f:\n",
    "        for i in range(classroom_size):\n",
    "            str_row = '{\\\"_id\\\":\\\"' + building_id + '-' + ('%03d' % (i+1)) + '\\\", \\\"info\\\": ['\n",
    "            for j in range(MAX_WEEK * 7 * 6):\n",
    "                if j != 0:\n",
    "                    str_row += ','\n",
    "                if info_list[i][j]:\n",
    "                    str_row += 'true'\n",
    "                else:\n",
    "                    str_row += 'false'\n",
    "            str_row += ']\\n'\n",
    "            f.write(str_row)\n",
    "\n",
    "def get_building_info(camp_id:str, building_id:str, building_name:str):\n",
    "    kjs_progress = tqdm_notebook(range(MAX_WEEK),desc=building_name)\n",
    "    info_list = [None] * MAX_WEEK\n",
    "    def process_html(future):\n",
    "        week, soup = future.result()\n",
    "#         print(week)\n",
    "        info_list[week-1]= table2array(soup)\n",
    "        kjs_progress.update(1)\n",
    "        \n",
    "    with concurrent.futures.ThreadPoolExecutor(MAX_THREAD_SIZE) as pool:\n",
    "        for i in range(MAX_WEEK):\n",
    "            temp = pool.submit(get_classroom_html, i+1, camp_id, building_id, use_vpn = USE_VPN)\n",
    "            temp.add_done_callback(process_html)\n",
    "        pool.shutdown(wait=True)\n",
    "        \n",
    "    classroom_size = len(info_list[0])\n",
    "    \n",
    "    def merge_list(l1, l2):\n",
    "        for i in range(classroom_size):\n",
    "            l1[i] = l1[i] + l2[i]\n",
    "        return l1\n",
    "    \n",
    "    info_list = functools.reduce(merge_list, info_list)\n",
    "    return info_list\n",
    "# temp_info_list = get_building_info('1', '016', '正心楼')\n",
    "def main():\n",
    "    with open(SQL_DIR + 'f1.json', 'r', encoding='utf-8') as f:\n",
    "        all_buildings = json.load(f)\n",
    "        for camp in all_buildings:\n",
    "            camp_id = str(camp['index'])\n",
    "            for building in camp['buildings']:\n",
    "                building_id, building_name = building['id'], building['name']\n",
    "                info_list = get_building_info(camp_id, building_id, building_name)\n",
    "                write2file(building_id, info_list)\n",
    "        with open(SQL_DIR + ALL_INFO_FILE, 'w') as fa:\n",
    "            for camp in all_buildings:\n",
    "                camp_id = str(camp['index'])\n",
    "                for building in camp['buildings']:\n",
    "                    building_id = ('%03d' % (int(building['id'])))\n",
    "                    file_path = SQL_DIR + 'room-info-' + building_id + '.json'\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        fa.write(f.read())\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正心楼\n",
      "主楼\n",
      "诚意楼\n",
      "格物楼\n",
      "理学楼\n",
      "致知楼\n",
      "管理学院楼\n",
      "学士楼\n",
      "新技术楼\n",
      "机械楼\n",
      "材料楼\n",
      "电机楼\n",
      "管理楼\n",
      "主楼\n",
      "东配楼\n",
      "西配楼\n",
      "车库楼\n",
      "青年公寓\n",
      "理化楼\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "def parse_room_name(tab_soup):\n",
    "    tab_soup = tab_soup[2:]\n",
    "    return list(map(lambda x: x('td')[0].text, tab_soup))\n",
    "\n",
    "def parse_floor(name_list, max_floor = 10, offset = 0):\n",
    "    floor_list = list([] for x in range(max_floor + 1))\n",
    "    index = 0\n",
    "    for room_name in name_list:\n",
    "        length = len(room_name)\n",
    "        floor, temp_floor, index = 0, 0, index + 1\n",
    "        start = offset\n",
    "        while room_name[start] < '1' or room_name[start] > '9':\n",
    "            start += 1\n",
    "            if (start + 1 >= length):\n",
    "                break\n",
    "        end = start + 1\n",
    "        while end < length:\n",
    "            if room_name[end] >= '0' and room_name[end] <= '9':\n",
    "                end += 1\n",
    "            else:\n",
    "                break\n",
    "        if room_name[start] >= '0' and room_name[start] <= '9':\n",
    "            temp_floor = int(room_name[start])\n",
    "            floor = temp_floor\n",
    "            if start + 2 <= end:\n",
    "                temp_floor *= 10\n",
    "                temp_floor += int(room_name[start+1])\n",
    "                if temp_floor <= max_floor and end - start >= 4:\n",
    "                    floor = temp_floor\n",
    "        floor_list[floor].append((index, room_name))\n",
    "    return floor_list\n",
    "\n",
    "def write2file_floor(building_id, floor_list):\n",
    "    building_id = ('%03d' % (int(building_id)))\n",
    "    file_path = SQL_DIR + building_id + '.json'\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(floor_list)):\n",
    "            if len(floor_list[i]) == 0:\n",
    "                continue\n",
    "            str_row, room_id, room_name = {}, [], []\n",
    "            str_row['_id'] = building_id + '-f' + str(i)\n",
    "            for ele in floor_list[i]:\n",
    "                room_id.append(building_id + '-%03d' % (ele[0]))\n",
    "                room_name.append(ele[1])\n",
    "            str_row['room-id'] = room_id\n",
    "            str_row['room-name'] = room_name\n",
    "            str_row = json.dumps(str_row, ensure_ascii=False)\n",
    "#             print(str_row)\n",
    "            f.write(str_row+ '\\n', )\n",
    "\n",
    "def get_floor():\n",
    "    with open(SQL_DIR + 'f2.json', 'r', encoding='utf-8') as f:\n",
    "        for xq in json.loads(f.read()):\n",
    "            camp_id = xq['index']\n",
    "            for building in xq['buildings']:\n",
    "                info_list = get_classroom_html(1, camp_id, building['id'], use_vpn = USE_VPN)\n",
    "                info_list = parse_room_name(info_list[1]('tr'))\n",
    "                info_list = parse_floor(info_list)\n",
    "                write2file_floor(building['id'], info_list)\n",
    "                print(building['name'])\n",
    "\n",
    "get_floor()\n",
    "# fl = parse_floor(rl)\n",
    "# write2file_floor('999', fl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
